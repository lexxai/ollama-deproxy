# Remote Ollama API endpoint (e.g., https://openwebui.example.com/ollama) (required)
REMOTE_URL=

# Authentication token for remote API (typically Bearer token format: "Bearer  YOUR_TOKEN_HERE")
REMOTE_AUTH_TOKEN=

# Logging level (e.g., DEBUG, INFO, WARNING, ERROR, CRITICAL) (default: INFO)
#LOG_LEVEL=INFO

# Enable HTTP/2 protocol for remote connections (default: True)
#REMOTE_URL_HTTP2=True

# Custom header to use for authentication (default: "Authorization")
#REMOTE_AUTH_HEADER=Authorization

# Local port to listen on (default: 11434)
#LOCAL_PORT=11434

# Request timeout for remote connections (in seconds; blank for no timeout)
#REMOTE_TIMEOUT=

# Stream responses from remote API (default: True)
#STREAM_RESPONSE=True

# Passthrough: Automatically decode `br` (Brotli) and `zstd` encoded responses (advanced, default: False)
#DECODE_RESPONSE=False

# Enable debugging for incoming requests (default: False)
#DEBUG_REQUEST=False

# If models are listed as numeric strings (e.g., "1", "2"), replace them with the corresponding model names from `ollama list` output (default: False)
# CORRECT_NUMBERED_MODEL_NAMES=False
